---
layout: blog 
title: "Week 4: Preliminary results"
---

## Overview

This week, we focused primarily on doing some preliminary investigations into
our datasets, and building several models.

## Overall methodology (and data characterization)

For this week, we focused on exploring Wikipedia's ["personal attacks" database][pad].
The database contains a collection of approximately 100,000 comments, each 
annotated by 5 workers indicating whether that comment contains a 
personal attack or not. This week, we labeled comments as an 'ATTACK' comment if
over 50% of the workers labeled it as containing an attack, and 'OK' otherwise,
and trained our model on this binary classification problem.

  [pad]: https://meta.wikimedia.org/wiki/Research:Detox/Data_Release#Wikipedia_Talk_Labels:_Personal_Attacks

We did some preliminary analysis on the dataset and discovered that...

- Approximately 85% of the comments were OK, approximately 15% were ATTACKs.
- The average number of words per comment is 87.3

During the next week, we plan on exploring our model against other aspects of the
dataset. In particular, the "personal attacks" dataset contains additional
information describing the nature of the attack. Wikipedia has also released
datasets measuring the level of aggression and toxicity, which we can explore.

## Bag-of-words model

We started by first implementing the basic model described within Wikipedia's
paper -- a bag-of-words model using tf-idf and logistic regression. We
obtained the following results:

| Metric    | Score     |
| --------- | --------- |
| Accuracy  | 0.940587  |
| Precision | 0.8927430 |
| Recall    | 0.569147  |
| F1        | 0.695035  |
| AUC       | 0.779942  |

We also obtained the following confusion matrix:

|        | OK    | ATTACK |
| ------ | ----- | ------ |
| OK     | 20216 | 189    |
| ATTACK | 1187  | 1568   |


## Character n-gram model

## LSTM + Bidirectional LSTM model

## Error analysis

## Upcoming work
