---
layout: blog 
title: "Week 8: Advanced models 2"
---

## Char RNN

We continued tweaking the character RNN, this time by applying both
max and average pooling to the convolution layer, and also by training
with increased positive loss to focus on recall over precision.

| Model | Accuracy | Precision | Recall | F1 | ROC | Spearman | Confusion Matrix |
| ----- | -------- | --------- | ------ | -- | --- | -------- | ---------------- |
| both max and<br />avg pool,<br />concatenated\* | 0.9398 | 0.8045 | 0.6526 | 0.7206 | 0.9413 | 0.6920 | `[19968   437]` <br> `[  957  1798]` |
| .1 dropout | 0.9336 | 0.7510 | 0.6613 | 0.7033 | 0.9325 | 0.6679 | `[19801   604]` <br> `[  933  1822]` |
| learning rate .0001\* | 0.9301 | 0.8661 | 0.4882 | 0.6244 | 0.9228 | 0.6187 | `[20197   208]` <br> `[ 1410  1345]` |
| pos weight 10 | 0.8581 | 0.4471 | 0.8138 |  0.5771 | 0.9211 | 0.5328 | `[17632  2773]` <br> `[  513  2242]` |
| pos weight 5\* | 0.8792 | 0.4951 | 0.7938 | 0.6099 | 0.9270 | 0.5641 | `[18175  2230]` <br> `[  568  2187]` |
| conv size 10 | 0.8970 | 0.5466 | 0.7855 | 0.6446 | 0.9344 | 0.5998 | `[18610  1795]` <br> `[  591  2164]` |
| double conv,<br />stride 2 | 0.8815 | 0.5012 | 0.7887 | 0.6129 | 0.9212 | 0.5666 | `[18242  2163]` <br> `[  582  2173]` |
| double conv,<br />stride 3 | 0.8946 | 0.5404 | 0.7590 | 0.6313 | 0.9211 | 0.5831 | `[18627  1778]` <br> `[  664  2091]` |
| double conv,<br />stride 2, but avgp<br />gets maxp at end | 0.9004 | 0.5639 | 0.7187 | 0.6320 | 0.9188 | 0.5810 | `[18874  1531]` <br> `[  775  1980]` |
| single conv: 5,<br />avg 10, then max<br />(no regular avgp) | 0.8591 | 0.4475 | 0.7877 | 0.5708 | 0.9099 | 0.5223 | `[17726  2679]` <br> `[  585  2170]` |
| single conv: 5,<br />avg 10 then max;<br />drop rate .05 | 0.8857 | 0.5131 | 0.7633 | 0.6137 | 0.9145 | 0.5645 | `[18409  1996]` <br> `[  652  2103]` |
| conv size 10;<br />split .25 | 0.7598 | 0.4775 | 0.8139 | 0.6019 | 0.8671 | 0.4786 | `[13390  4602]` <br> `[  962  4206]` |

Note: 

1. \* indicates that following runs used the same change

   (For the double convolutions, there were actually two "second layers"; one that used the max pooling from the first layer and had max pooling applied at the end, and another that used avg pooling and had avg pooling applied at the end.)
   
2. \*\* For these three, max pooling (over all values) as applied after average pooling (stride 1, size 10); for the double convolution, the max pool half of the second layer was left alone, but for the single convolution, it was removed entirely.

Apparently, the larger convolution size performs better than trying to apply a second convolution layer.
Also, as expected, with the lower split, the recall is better than before, but the precision is significantly worse. We still haven't tried using 0.0 splitting on these versions, as described in the next section.

## Altering attack classification threshold

Previously, we were classifying our data as attack/not-attack using a 0.5 split -- we
classified a comment as an attack if more than 50% of reviewers agreed it was an attack.

This week, we experimented with a 0.0 split -- that is, we classified a comment as an
attack if any *single* annotator considered it an attack. This has the net effect of
making our classifier possibly hyper-sensitive to possible attacks/abuse, but we
thought it was a worthwhile tradeoff, in part because it helps balance our dataset
(we now have 11551 comments classified as not-attack and 11609 classified as attack
in our train dataset), and in part because pragmatically a hyper-sensitive classifier
is likely potentially just as useful as one that isnâ€™t, given some human oversight.

We obtained the following results. As before, logistic regression and bag-of-words are
slightly out-performing our deep learning models. However, we still feel we have a
decent amount of work left to be done -- in particular, we plan on conducting more
in-depth error analysis of this adjusted dataset in the near future.

<table>
  <thead>
    <tr>
      <th>Classifier</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
      <th>ROC</th>
      <th>Spearman</th>
      <th>Confusion Matrix</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Profanity filter<br /> (substring)</td>
      <td>0.5889</td><td>0.6696</td><td>0.3552</td>
      <td>0.4641</td><td>0.5895</td><td>0.2027</td>
      <td><code>[9517 2034]</code><br /><code>[7486 4123]</code></td>
    </tr>
    <tr>
      <td>Profanity filter<br /> (split on words)</td>
      <td>0.5567</td><td>0.9602</td><td>0.1207</td>
      <td>0.2144</td><td>0.5578</td><td>0.2380</td>
      <td><code>[11493 &nbsp;&nbsp;58]</code><br /><code>[10208  1401]</code></td>
    </tr>
    <tr>
      <td>Bag of words</td>
      <td>0.7541</td><td>0.7817</td><td>0.7070</td>
      <td>0.7424</td><td>0.8271</td><td>0.5108</td>
      <td><code>[9259 2292]</code><br /><code>[3402 8207]</code></td>
    </tr>
    <tr>
      <td>Logistic<br /> regression</td>
      <td>0.7522</td><td>0.7698</td><td>0.7215</td>
      <td>0.7449</td><td>0.8269</td><td>0.5056</td>
      <td><code>[9046 2505]</code><br /><code>[3233 8376]</code></td>
    </tr>
    <tr>
      <td>Word RNN</td>
      <td>0.6710</td><td>0.6405</td><td>0.67831</td>
      <td>0.0747</td><td>0.7496</td><td>0.3504</td>
      <td><code>[6449 5102]</code><br /><code>[2518 9091]</code></td>
    </tr>
    <tr>
      <td>Character RNN</td>
      <td>0.7071</td><td>0.7140</td><td>0.6934</td>
      <td>0.7036</td><td>0.7817</td><td>0.4145</td>
      <td><code>[8327 3224]</code><br /><code>[3559 8050]</code></td>
    </tr>
  </tbody>
</table>

Interestingly, we were able to obtain slightly better results when classifying attacks
(at the expense of increasing the rate of false positives) under some hyperparameters.
The main change we made to do this was to add batch normalization -- we plan on doing
more testing to see if the better results was simply an abnormal quirk or not.

## Stanford Politeness Corpus

We also experimented with other corpora -- in particular, the Stanford
Politeness Corpus. This corpus contains a collection of "requests" one
user made to another collected from Wikipedia and StackOverflow, along
with annotations recording the perceived politeness of the requests.

This is a comparatively smaller dataset compared to our Wikipedia corpus
-- it contains only a little over 10,000 entries overall, which is an
order of magnitude smaller then the Wikipedia corpus. We obtained our
train, dev, and test sets by shuffling the entries and splitting them
80%-20%-20%.

We then classified any entries with a normalized politeness score over
0.6 as being "polite"-- this produced an approximately 50-50 split.
We then obtained the following results:

<table>
  <thead>
    <tr>
      <th>Classifier</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1</th>
      <th>ROC</th>
      <th>Spearman</th>
      <th>Confusion Matrix</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Profanity filter<br /> (substring)</td>
      <td>0.4870</td><td>0.5489</td><td>0.0884</td>
      <td>0.1523</td><td>0.5047</td><td>0.0168</td>
      <td><code>[ 966   83]</code><br /><code>[1041  101]</code></td>
    </tr>
    <tr>
      <td>Profanity filter<br /> (split on words)</td>
      <td>0.4783</td><td>0.4000</td><td>0.0018</td>
      <td>0.0035</td><td>0.4994</td><td>-0.0116</td>
      <td><code>[1046  3]</code><br /><code>[1140  2]</code></td>
    </tr>
    <tr>
      <td>Bag of words</td>
      <td>0.6568</td><td>0.6533</td><td>0.7277</td>
      <td>0.6885</td><td>0.7174</td><td>0.3111</td>
      <td><code>[608 441]</code><br /><code>[311 831]</code></td>
    </tr>
    <tr>
      <td>Logistic regression</td>
      <td>0.6244</td><td>0.6360</td><td>0.6532</td>
      <td>0.6445</td><td>0.6780</td><td>0.2466</td>
      <td><code>[622 427]</code><br /><code>[396 746]</code></td>
    </tr>
    <tr>
      <td>Word RNN</td>
      <td>0.5860</td><td>0.5995</td><td>0.6200</td>
      <td>0.6096</td><td>0.6171</td><td>0.1694</td>
      <td><code>[576 473]</code><br /><code>[434 708]</code></td>
    </tr>
    <tr>
      <td>Character RNN</td>
      <td>0.6016</td><td>0.5959</td><td>0.7320</td>
      <td>0.6570</td><td>0.6483</td><td>0.1994</td>
      <td><code>[482 567]</code><br /><code>[306 836]</code></td>
    </tr>
  </tbody>
</table>
